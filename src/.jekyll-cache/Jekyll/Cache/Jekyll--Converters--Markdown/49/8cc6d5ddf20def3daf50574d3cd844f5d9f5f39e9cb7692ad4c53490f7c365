I"Ç<h3 id="award-nomination"><strong>Award Nomination</strong></h3>

<p>Our paper at ICRA was nominated as a Award finalist for <a href="https://www.icra2019.org/program/awards"><strong>Best Paper</strong> and <strong>Best Cognitive Robotics Paper Award</strong></a>. And it won the <strong>Best Paper</strong> award for ICRA 2019.</p>

<ul>
  <li><strong><a href="https://arxiv.org/abs/1810.10191">Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks</a></strong><br />
  Michelle A. Lee*, Yuke Zhu*, Krishnan Srinivasan, Parth Shah, Silvio Savarese, Li Fei-Fei, <strong>Animesh Garg</strong>, Jeannette Bohg.<br />
  [<a href="https://arxiv.org/abs/1810.10191">arXiv 1810.10191</a>]. [<a href="https://sites.google.com/view/visionandtouch">Project Webpage</a>]</li>
</ul>

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr">We won the best paper award <a href="https://twitter.com/michellearning?ref_src=twsrc%5Etfw">@michellearning</a> <a href="https://twitter.com/yukez?ref_src=twsrc%5Etfw">@yukez</a> <a href="https://twitter.com/leto__jean?ref_src=twsrc%5Etfw">@leto__jean</a> <a href="https://twitter.com/drfeifei?ref_src=twsrc%5Etfw">@drfeifei</a> <a href="https://twitter.com/silviocinguetta?ref_src=twsrc%5Etfw">@silviocinguetta</a> <a href="https://t.co/QfMulDCjVe">pic.twitter.com/QfMulDCjVe</a></p>&mdash; Animesh Garg (@animesh_garg) <a href="https://twitter.com/animesh_garg/status/1131263955622604801?ref_src=twsrc%5Etfw">May 22, 2019</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Please feel free to send me an email with comments and suggestions.</p>
:ET